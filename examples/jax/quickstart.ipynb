{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uCEQLS3zZUn"
      },
      "source": [
        "# JAX Mava Quickstart Notebook\n",
        "<img src=\"https://raw.githubusercontent.com/instadeepai/Mava/develop/docs/images/mava.png\" />\n",
        "\n",
        "### This notebook provides an easy introducion to the [Mava](https://github.com/instadeepai/Mava) framework by showing how to construct a multi-agent system, and train it from scratch in a simple evironment. \n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/instadeepai/Mava/blob/develop/examples/jax/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEAq7x7ff1fE"
      },
      "source": [
        "### 1. Installing packages"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by installing the necessary packages."
      ],
      "metadata": {
        "id": "7gXH-DtX6OtI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl4ed6X22tZq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Install required packages. (Run Cell)\n",
        "! rm -r ./Mava\n",
        "! git clone https://github.com/instadeepai/Mava.git\n",
        "!pip install ./Mava[reverb,jax,launchpad,envs]\n",
        "\n",
        "# Installs for agent visualisation.\n",
        "!pip install ./Mava[record_episode]\n",
        "! apt-get update -y &&  apt-get install -y xvfb &&  apt-get install -y python-opengl && apt-get install ffmpeg && pip install pyvirtualdisplay \n",
        "# Google colab has an old version of cloudpickle - issue with lp.  \n",
        "!pip install cloudpickle -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SGFGmWnhuI2"
      },
      "source": [
        "### 2. Import the necessary modules"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary modules that will be used to construct the multi-agent system and visualise the agents."
      ],
      "metadata": {
        "id": "GjPRSgi56Mi7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SvWrsWExz31",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import required packages. (Run Cell)\n",
        "import functools\n",
        "from datetime import datetime\n",
        "from typing import Any\n",
        "\n",
        "import optax\n",
        "from absl import app, flags\n",
        "\n",
        "from mava.systems.jax import mappo\n",
        "from mava.utils.environments import debugging_utils\n",
        "from mava.utils.loggers import logger_utils\n",
        "from mava.components.jax.building.environments import MonitorExecutorEnvironmentLoop\n",
        "\n",
        "# Imports for agent visualisation\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "os.environ[\"DISPLAY\"] = \":\" + str(display.display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul_phKL7h4Vq"
      },
      "source": [
        "### 3. Train a multi-agent `PPO` system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8XqA9M2iyK_"
      },
      "source": [
        "We start by defining the networks and network optimizer for our agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ4-cN2dkXjq"
      },
      "outputs": [],
      "source": [
        "# Create the network factory.\n",
        "def network_factory(*args: Any, **kwargs: Any) -> Any:\n",
        "    return mappo.make_default_networks(  # type: ignore\n",
        "        policy_layer_sizes=(254, 254, 254),\n",
        "        critic_layer_sizes=(512, 512, 256),\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    )\n",
        "  \n",
        "# Optimizer.\n",
        "optimizer = optax.chain(\n",
        "    optax.clip_by_global_norm(40.0), optax.scale_by_adam(), optax.scale(-1e-4)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohA5m0REjhu-"
      },
      "source": [
        "We now select the environment we want to train on. We will use the [simple spread](https://github.com/instadeepai/Mava#debugging) environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw_4dR1jj-Wv"
      },
      "outputs": [],
      "source": [
        "env_name = \"simple_spread\"\n",
        "action_space = \"discrete\"\n",
        "\n",
        "environment_factory = functools.partial(\n",
        "    debugging_utils.make_environment,\n",
        "    env_name=env_name,\n",
        "    action_space=action_space,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avvSeVahk_Nt"
      },
      "source": [
        "Next, we specify the logging and checkpointing configuration for our system. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8J05yDlk-ya"
      },
      "outputs": [],
      "source": [
        "# Directory to store checkpoints and log data. \n",
        "base_dir = \"~/mava\"\n",
        "\n",
        "# File name \n",
        "mava_id = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to experiment_path\n",
        "experiment_path = f\"{base_dir}/{mava_id}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i3tj4h-lTm4"
      },
      "source": [
        "Finally, we construct our multi-agent PPO system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS618jAtxM1h"
      },
      "outputs": [],
      "source": [
        "# Create the system.\n",
        "system = mappo.MAPPOSystem()\n",
        "\n",
        "# Add the gameplay monitor component\n",
        "system.update(MonitorExecutorEnvironmentLoop)\n",
        "\n",
        "# Build the system.\n",
        "system.build(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    experiment_path=experiment_path,\n",
        "    optimizer=optimizer,\n",
        "    run_evaluator=True,\n",
        "    sample_batch_size=20,\n",
        "    num_epochs=15,\n",
        "    num_executors=1,\n",
        "    multi_process=False,\n",
        "    single_process_max_episodes=500,\n",
        "    record_every=1,\n",
        " )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example we use MAPPO which is already implemented inside Mava. However, we add the `MonitorExecutorEnvironmentLoop` component to record episodes for later inspection. Mava is designed with flexibility in mind and allow users to easily build on top of existing systems. A system is just a collection of components, which can be though of as self-contained pieces of code (building block) that add functionality to a system. The MAPPO system's components can be found [here](https://github.com/instadeepai/Mava/blob/develop/mava/systems/jax/mappo/system.py)."
      ],
      "metadata": {
        "id": "fH3u39Cfa-bQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBWiibHIleQk"
      },
      "source": [
        "We now run our system for 500 episodes. The `system.launch` method initialise and runs an executor (experience generator), a trainer (network updater), data server and parameter server process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsoLWPTClnMt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Launch the system.\n",
        "system.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHygoBPW-3KV"
      },
      "source": [
        "### 4. Visuallise our training results using Tensorboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the tensorboard exension. You will need to wait for the system to complete its 500 episodes."
      ],
      "metadata": {
        "id": "VAGEzi_rWhOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l181SBwtBo9M"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJl7LKmHAOk-"
      },
      "source": [
        "To view training results, start tensorboard and point it to where we specified Mava should log to (~/mava/$mava_id).\n",
        "\n",
        "A good score is a `RawEpisodeReturn` between 30-40. Although this system is stochastic, it should atleast reach that score by 500 executor episodes.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fU3yEhdFx1O"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir ~/mava/$mava_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDlUXGltyVhM"
      },
      "source": [
        "### 5. View agent recordings\n",
        "Once a good score is reached, you can view the learned multi-agent behaviour by viewing the agent recordings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2l8o2zDBbuN"
      },
      "source": [
        "#### Check if any agent recordings are available. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXB1IKfysMT6"
      },
      "outputs": [],
      "source": [
        "! ls ~/mava/$mava_id/recordings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjcnXbl7BfJc"
      },
      "source": [
        "#### View the latest agent recording. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEEshoXd2K1S"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os \n",
        "import IPython\n",
        "\n",
        "# Recordings\n",
        "list_of_files = glob.glob(f\"/root/mava/{mava_id}/recordings/*.html\")\n",
        "\n",
        "if(len(list_of_files) == 0):\n",
        "  print(\"No recordings are available yet. Please wait or run the 'Run Multi-Agent PPO System.' cell if you haven't already done this.\")\n",
        "else:\n",
        "  latest_file = max(list_of_files, key=os.path.getctime)\n",
        "  print(\"Run the next cell to visualize your agents!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ33l0uIJ9xB"
      },
      "source": [
        "If the agents are trained (*usually around 500 episodes...*), they should move to the assigned landmarks.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/instadeepai/Mava/develop/docs/images/simple_spread.png\" width=\"250\" height=\"250\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95GOv5vc5z5Q"
      },
      "outputs": [],
      "source": [
        "# Latest file needs to point to the latest recording\n",
        "IPython.display.HTML(filename=latest_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! You have now trained a multi-agent system in Mava."
      ],
      "metadata": {
        "id": "ryQ9EhumnGBS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYekMtHB26yL"
      },
      "source": [
        "## What's next?\n",
        "Mava is explicitly designed to make it easy to build custom multi-agent systems. As mentioned above, each system is just a combination of various [components](https://github.com/instadeepai/Mava/tree/develop/mava/components/jax). These components place self-contained pieces of code at selective places (called hooks) in the system. Each of these hook function names start with the `on` keyword. When the system is building it calls the hooks inside the [builder](https://github.com/instadeepai/Mava/blob/develop/mava/systems/jax/builder.py), and when it is executing it calls the hooks inside the [executor](https://github.com/instadeepai/Mava/blob/develop/mava/systems/jax/executor.py), [trainer](https://github.com/instadeepai/Mava/blob/develop/mava/systems/jax/trainer.py) and [parameter_server](https://github.com/instadeepai/Mava/blob/develop/mava/systems/jax/parameter_server.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now try and build our own custom component and add that to the PPO implementation.  We will update the [advantage estimation component](https://github.com/instadeepai/Mava/blob/develop/mava/components/jax/training/advantage_estimation.py) with a simpler advantage estimate and overwrite the `on_training_utility_fns` located in the [trainer](https://github.com/instadeepai/Mava/blob/develop/mava/systems/jax/trainer.py#L45). This component creates a function called `gae_fn` which is called by the system to calculate an [advantage estimate](https://towardsdatascience.com/generalized-advantage-estimate-maths-and-code-b5d5bd3ce737) when training."
      ],
      "metadata": {
        "id": "darfOQL1aSo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by defining our new component below. Notice that we store our new advantage function inside `trainer.store.gae_fn`. The `store` is a place where components can save variables for other components to access."
      ],
      "metadata": {
        "id": "IKPKCqB21XMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Trainer components for advantage calculations.\"\"\"\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, List, Optional, Tuple, Type\n",
        "from mava.components.jax.training.advantage_estimation import GAE\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import rlax\n",
        "\n",
        "from mava.callbacks import Callback\n",
        "from mava.components.jax.training.base import Utility\n",
        "from mava.core_jax import SystemTrainer\n",
        "\n",
        "@dataclass\n",
        "class AConfig:\n",
        "    a_lambda: float = 0.95\n",
        "\n",
        "\n",
        "class simpler_advantage_estimate(GAE):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config: AConfig = AConfig(),\n",
        "    ):\n",
        "        self.config = config\n",
        "\n",
        "    def on_training_utility_fns(self, trainer: SystemTrainer) -> None:\n",
        "        def simpler_advantage_estimate(\n",
        "            rewards: jnp.ndarray, discounts: jnp.ndarray, values: jnp.ndarray\n",
        "        ) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "\n",
        "\n",
        "            # Instead of using the GAE we use a simpler one step\n",
        "            # advantage estimate.\n",
        "\n",
        "            # Pad the rewards so that rewards at the end can also be calculated.\n",
        "            zeros_mask = jnp.zeros(shape=rewards.shape)\n",
        "            padded_rewards = jnp.concatenate([rewards, zeros_mask], axis=0)\n",
        "            cum_rewards = rewards.copy()\n",
        "            seq_len = len(rewards)\n",
        "            for i in range(1, seq_len):\n",
        "                cum_rewards+=padded_rewards[i : i +seq_len]\\\n",
        "                              *jnp.power(self.config.a_lambda, i)\n",
        "\n",
        "            # Calculate the advantage estimate.\n",
        "            advantages = cum_rewards[:-1] - values[:-1]\n",
        "            \n",
        "            # Stop gradients from flowing through the advantage estimate.\n",
        "            advantages = jax.lax.stop_gradient(advantages)\n",
        "\n",
        "            # Set the target values and stop gradients from flowing backwards\n",
        "            # through the target values.\n",
        "            target_values = cum_rewards[:-1]\n",
        "            target_values = jax.lax.stop_gradient(target_values)\n",
        "\n",
        "            return advantages, target_values\n",
        "\n",
        "        trainer.store.gae_fn = simpler_advantage_estimate\n",
        "\n",
        "    @staticmethod\n",
        "    def name() -> str:\n",
        "        return \"gae_fn\"\n",
        "\n",
        "    @staticmethod\n",
        "    def config_class() -> Optional[Callable]:\n",
        "        return AConfig"
      ],
      "metadata": {
        "id": "A0HOxOnVmq93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have this new component we can add it to the PPO system using `system.update`. You can retrain the system by executing the cell below. Once training is complete you can again run steps 4 and 5 (above) to view the training results and gameplay footage. Does this system perform better or worse than the previous system? \n",
        "\n",
        "Feel free to update the advantage component to see if you can achieve better training results. For more examples using different systems, environments and architectures, visit our [github page](https://github.com/instadeepai/Mava/tree/develop/examples/tf)."
      ],
      "metadata": {
        "id": "dcYvshTpmu_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File name \n",
        "mava_id = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "# Log every [log_every] seconds\n",
        "log_every = 15\n",
        "logger_factory = functools.partial(\n",
        "    logger_utils.make_logger,\n",
        "    directory=base_dir,\n",
        "    to_terminal=True,\n",
        "    to_tensorboard=True,\n",
        "    time_stamp=mava_id,\n",
        "    time_delta=log_every,\n",
        ")\n",
        "\n",
        "# Checkpointer appends \"Checkpoints\" to experiment_path\n",
        "experiment_path = f\"{base_dir}/{mava_id}\"\n",
        "\n",
        "# Create the system.\n",
        "system = mappo.MAPPOSystem()\n",
        "\n",
        "# Add the gameplay monitor component\n",
        "system.update(MonitorExecutorEnvironmentLoop)\n",
        "\n",
        "# Update the system with out custom component.\n",
        "system.update(simpler_advantage_estimate)\n",
        "\n",
        "# Build the system.\n",
        "system.build(\n",
        "    environment_factory=environment_factory,\n",
        "    network_factory=network_factory,\n",
        "    logger_factory=logger_factory,\n",
        "    experiment_path=experiment_path,\n",
        "    optimizer=optimizer,\n",
        "    run_evaluator=True,\n",
        "    sample_batch_size=5,\n",
        "    num_epochs=15,\n",
        "    num_executors=1,\n",
        "    multi_process=False,\n",
        "    single_process_max_episodes=500,\n",
        "    record_every=10,\n",
        " )\n",
        "\n",
        "# Launch the system.\n",
        "system.launch()"
      ],
      "metadata": {
        "id": "p9efhqaiq-QL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Mava_JAX_Quickstart.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}